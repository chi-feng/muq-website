{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimizing the Rosenbrock function\n",
    "MUQ contsins methods for solving both constrained and unconstrained optimization problems.  Here we demonstrate some of the unconstrained optimization capabilities in MUQ by minimizing the Rosenbrock function.  \n",
    "\n",
    "Let $x\\in\\mathbb{R}^2$ denote the two dimensional decision variable and let $f(x)$ denote the objective function, which is given by the well known Rosenbrock function\n",
    "\n",
    "$$\n",
    "f(x) = \\left(1 - x_1\\right)^2 + 100(x_2-x_1^2)^2\n",
    "$$\n",
    "\n",
    "This function has a global minimum at $x=[x_1,x_2] = [1,1]$.\n",
    "\n",
    "## Optimization in MUQ\n",
    "In MUQ, optimization problems are defined as children of the abstract `muq::Optimization::OptProbBase` class. Thus, to define the Rosenbrock problem, we need inherit from this class and implement the objective function.  An instance of this class can then be passed to an optimization algorithm (defined through children of the `muq::Optimization::OptAlgBase` class).\n",
    "\n",
    "## Include the necessary header files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting RosenbrockOpt.cpp\n"
     ]
    }
   ],
   "source": [
    "%%writefile RosenbrockOpt.cpp\n",
    "#include <Eigen/Dense>\n",
    "\n",
    "#include \"MUQ/Optimization/Problems/OptProbBase.h\"\n",
    "#include \"MUQ/Optimization/Algorithms/OptAlgBase.h\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the objective\n",
    "Here we define a class, called `RoseFunc` that inherits from the optimization base class [`muq::Optimization::OptProbBase`](http://muq.mit.edu/develop-docs/classmuq_1_1Optimization_1_1OptProbBase.html). \n",
    "\n",
    "### Constructor\n",
    "The constructor of [`muq::Optimization::OptProbBase`](http://muq.mit.edu/develop-docs/classmuq_1_1Optimization_1_1OptProbBase.html) accepts the number of decision variables (2 in this case).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to RosenbrockOpt.cpp\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a RosenbrockOpt.cpp\n",
    "\n",
    "class RoseFunc : public muq::Optimization::OptProbBase {\n",
    "public:\n",
    "\n",
    "  RoseFunc() : muq::Optimization::OptProbBase(2) {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective function, i.e. `eval`\n",
    "All user-defined objective functions must define the objective function by implementing the [`eval`](http://muq.mit.edu/develop-docs/classmuq_1_1Optimization_1_1OptProbBase.html#a9767e98e98ea39a00761dc26b3257b42) function.  Here, we create the objective function for the Rosenbrock function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to RosenbrockOpt.cpp\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a RosenbrockOpt.cpp\n",
    "  virtual double eval(const Eigen::VectorXd& xc) override\n",
    "  {\n",
    "    return pow(1 - xc[0], 2) + 100 * pow(xc[1] - xc[0] * xc[0], 2);\n",
    "  }\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Gradients and Hessians\n",
    "Some optimizers can take advantage of gradient and Hessian information.  This information is provied by implementing the [`grad`](http://muq.mit.edu/develop-docs/classmuq_1_1Optimization_1_1OptProbBase.html#a0b4e3e33330be57235c6edd097ecf2b0) and [`applyInvHess`](http://muq.mit.edu/develop-docs/classmuq_1_1Optimization_1_1OptProbBase.html#a70415b59ca2d61e8a82cdf869294b9c3) functions.  Note that both of these functions are optional and will be replaced by finite difference approximations if they are not provided.\n",
    "\n",
    "The gradient is given by\n",
    "\n",
    "$$\n",
    "\\nabla f(x) = \\left[ \\begin{array}{c} -2(1-x_1) - 400x_1\\left(x_2-x_1^2\\right) \\\\ 200\\left(x_2-x_1^2\\right) \\end{array}\\right]^T .\n",
    "$$\n",
    "\n",
    "The [`grad`](http://muq.mit.edu/develop-docs/classmuq_1_1Optimization_1_1OptProbBase.html#a0b4e3e33330be57235c6edd097ecf2b0) function computes updates the gradient, which is passed by reference, and returns the objective function value.  In some cases, computing these quantities at the same time can be more computationally efficient.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to RosenbrockOpt.cpp\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a RosenbrockOpt.cpp\n",
    "\n",
    "  virtual double grad(const Eigen::VectorXd& xc, Eigen::VectorXd& gradient) override\n",
    "  {\n",
    "    gradient.resize(2);\n",
    "    \n",
    "    gradient[0] = -400 * (xc[1] - xc[0] * xc[0]) * xc[0] - 2 * (1 - xc[0]);\n",
    "    gradient[1] = 200 * (xc[1] - xc[0] * xc[0]);\n",
    "\n",
    "    return eval(xc);\n",
    "  }\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Hessian matrix of the Rosenbrock function is given by\n",
    "\n",
    "$$\n",
    "H(x) = \\left[ \\begin{array}{cc} 2 - 400x_2 + 1200x_1^2 & -400x_1 \\\\ -400x_1 & 200\\end{array}\\right].\n",
    "$$\n",
    "\n",
    "Notice that the [`applyInvHess`](http://muq.mit.edu/develop-docs/classmuq_1_1Optimization_1_1OptProbBase.html#a70415b59ca2d61e8a82cdf869294b9c3) function applies the inverse Hessian to a matrix and does not return the actual Hessian matrix.  This allows for flexibility in how the inverse action is computed (e.g., adjoint methods with iterative solvers).  However, for some users it may be more convenient to simply return the Hessian or inverse Hessian.  In these situations, users can instead overload the `getHess` and [`getInvHess`](http://muq.mit.edu/develop-docs/classmuq_1_1Optimization_1_1OptProbBase.html#af870584a59f511648c31263be3ab2391) functions.  Note that the [`getHess`](http://muq.mit.edu/develop-docs/classmuq_1_1Optimization_1_1OptProbBase.html#a83ac19fa761198ab1bbdf5622c56c095) or `getInvHess` functions will not be used if the [`applyInvHess`](http://muq.mit.edu/develop-docs/classmuq_1_1Optimization_1_1OptProbBase.html#a70415b59ca2d61e8a82cdf869294b9c3) function is implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to RosenbrockOpt.cpp\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a RosenbrockOpt.cpp\n",
    "  virtual Eigen::VectorXd applyInvHess(const Eigen::VectorXd& xc, const Eigen::VectorXd& vecIn)\n",
    "  {\n",
    "    Eigen::Matrix<double, 2, 2> Hess = Eigen::Matrix<double, 2, 2>::Zero(2, 2);\n",
    "\n",
    "    Hess(0, 0) = 1200 * pow(xc[0], 2.0) - 400 * xc[1] + 2;\n",
    "    Hess(0, 1) = -400 * xc[0];\n",
    "    Hess(1, 0) = -400 * xc[0];\n",
    "    Hess(1, 1) = 200;\n",
    "\n",
    "    return Hess.lu().solve(vecIn);\n",
    "  }\n",
    "  \n",
    "}; // End of RoseFunc class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving the problem\n",
    "Now that we've defined our problem in the `RoseFunc` class, we can set up an optimizer and minimize the objective function.\n",
    "\n",
    "### Create an instance of the objective\n",
    "We begin the main function here by creating an instance of the Rosenbrock optimization function defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to RosenbrockOpt.cpp\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a RosenbrockOpt.cpp\n",
    "\n",
    "\n",
    "int main()\n",
    "{\n",
    "\n",
    "    // create an instance of the optimization problem\n",
    "    auto prob = std::make_shared<RoseFunc>();\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the optimizer\n",
    "Now we create an optimizer.  MUQ uses the factory method [`muq::Optimization::OptAlgBase::Create`](http://muq.mit.edu/develop-docs/classmuq_1_1Optimization_1_1OptAlgBase.html#a95bb02137929d87b1fd3bbd1b81f190e) to construct an optimizer based on the problem and other optimization parameters defined in a [`boost::property_tree::ptree`](http://www.boost.org/doc/libs/1_57_0/doc/html/property_tree.html).\n",
    "\n",
    "The optimization algorithm, set by the `Opt.Method` parameter, can be one of \n",
    "- `SD_Line`, which will create a steepest descent solver\n",
    "- `BFGS_Line`, which will create a BFGS solver\n",
    "- `Newton`, which will create a Newton solver\n",
    "\n",
    "If MUQ was compiled with NLOPT.  It is also possible to set `Opt.Method` to `NLOPT`.   The specific optimization algorithm is then specified by the `Opt.NLOPT.Method` key.   See the parameter list [here](http://muq.mit.edu/develop-docs/parameters.html) for more options.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to RosenbrockOpt.cpp\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a RosenbrockOpt.cpp\n",
    "\n",
    "    // set the initial condition\n",
    "    Eigen::VectorXd x0(2);\n",
    "    x0 << -1, 3;\n",
    "\n",
    "    boost::property_tree::ptree params;\n",
    "\n",
    "    // set some of the optimization parameters\n",
    "    params.put(\"Opt.MaxIts\", 10000);\n",
    "    params.put(\"Opt.ftol\", 1e-8);\n",
    "    params.put(\"Opt.xtol\", 1e-8);\n",
    "    params.put(\"Opt.gtol\", 1e-8);\n",
    "    params.put(\"Opt.LineSearch.LineIts\", 100);\n",
    "    params.put(\"Opt.StepLength\", 1);\n",
    "    params.put(\"Opt.verbosity\", 3);\n",
    "    \n",
    "    //params.put(\"Opt.Method\", \"SD_Line\");    // Use the steepest descent algorithm\n",
    "    //params.put(\"Opt.Method\", \"BFGS_Line\");  // Use the BFGS algorithm\n",
    "    params.put(\"Opt.Method\", \"Newton\");     // Use the Newton algorithm\n",
    "\n",
    "    // set up the solver\n",
    "    auto Solver = muq::Optimization::OptAlgBase::Create(prob, params);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the optimizer\n",
    "The [`OptAlgBase::solve`](http://muq.mit.edu/develop-docs/classmuq_1_1Optimization_1_1OptAlgBase.html#aecf927c9593b1116604dd7b9087478d2) function runs the optimization algorithm and, upon successful completion, returns the optimal point.  \n",
    "\n",
    "The termination status of the solver can be checked with the [`OptAlgBase::GetStatus`](http://muq.mit.edu/develop-docs/classmuq_1_1Optimization_1_1OptAlgBase.html#abfc9e5df1faf77d244fc1f2466ba2ade) function.  Note that MUQ's termination codes are identical to NLOPT: positive numbers indicate successful termination and negative numbers indicate that an error occured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to RosenbrockOpt.cpp\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a RosenbrockOpt.cpp\n",
    "\n",
    "    // solve the optimization problem\n",
    "    Eigen::VectorXd xOpt = Solver->solve(x0);\n",
    "\n",
    "    // Get the termination status\n",
    "    int optStat = Solver->GetStatus();\n",
    "\n",
    "    std::cout << \"Optimal solution = \" << xOpt.transpose() << std::endl;\n",
    "    \n",
    "    return 0;\n",
    "} // End of \"int main()\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning dependencies of target RosenbrockOpt\n",
      "[100%] Building CXX object CMakeFiles/RosenbrockOpt.dir/RosenbrockOpt.cpp.o\n",
      "Linking CXX executable RosenbrockOpt\n",
      "[100%] Built target RosenbrockOpt\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "cd build; cmake ../ > BuildLog.txt; make; cd ../"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using optimization method: Newton\n",
      "Iteration: 1   fval: 404\n",
      "Iteration: 2   fval: 4.02008\n",
      "Iteration: 3   fval: 3.46927\n",
      "Iteration: 4   fval: 2.66982\n",
      "Iteration: 5   fval: 2.25626\n",
      "Iteration: 6   fval: 1.71473\n",
      "Iteration: 7   fval: 1.40064\n",
      "Iteration: 8   fval: 0.943349\n",
      "Iteration: 9   fval: 0.754829\n",
      "Iteration: 10   fval: 0.488025\n",
      "Iteration: 11   fval: 0.362813\n",
      "Iteration: 12   fval: 0.223237\n",
      "Iteration: 13   fval: 0.133336\n",
      "Iteration: 14   fval: 0.0661269\n",
      "Iteration: 15   fval: 0.0353271\n",
      "Iteration: 16   fval: 0.0098764\n",
      "Iteration: 17   fval: 0.00387419\n",
      "Iteration: 18   fval: 0.000141491\n",
      "Iteration: 19   fval: 1.87429e-06\n",
      "Iteration: 20   fval: 1.63594e-19\n",
      "Terminating with status: 3\n",
      "Optimal solution = 1 1\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "build/RosenbrockOpt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
